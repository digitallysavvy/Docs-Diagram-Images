The image displays a flowchart diagram detailing the processes involved in using a voice SDK to handle audio communication in an app. The diagram is broken down into different sections with clear steps for each part of the communication process:

1. **Create a local client**: This step involves initializing the client in Real-Time Communications (RTC) mode using the `AgoraRTC.createClient` method.

2. **Join channel**: Here, the app client joins a communication channel using the `AgoraRTCClient.join` method. There's also a corresponding "Join channel request" to the Agora SD-RTN (Software-Defined Real-Time Network) on the right side of the diagram.

3. **Create and publish local audio track**: 
   - A local audio track is created using `AgoraRTC.createMicrophoneAudioTrack`.
   - This track is then published to the channel using `AgoraRTCClient.publish`.
   - Simultaneously, audio data is sent to Agora SD-RTN.

4. **Subscribe to remote users**:
   - First, the app detects when remote users publish an audio track, as indicated by the `client.on("user-published")` event.
   - The app then gets the remote user object and subscribes to their audio stream using `AgoraRTCClient.subscribe`.
   - Audio data is received from the subscribed users.

5. **Leave the channel**:
   - The local audio track is turned off using `MicrophoneAudioTrack.close`.
   - The client leaves the channel with `AgoraRTCClient.leave`, and a request to leave the channel is sent to Agora SD-RTN.

This diagram appears to be part of documentation or a development guide, providing a visual representation of how to integrate and control audio communication using the Agora Voice SDK in an application.